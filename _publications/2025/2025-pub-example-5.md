---
title:          "Large Language Models Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Large Research Language Models"
date:           2025-07-26 00:01:00 +0800
selected:       true
pub:            "ACL"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Oral</span>'
pub_date:       "2025"

abstract: >-
  A common use of NLP is to facilitate the understanding of large document collections, with models based on Large Language Models (LLMs) replacing probabilistic topic models. Yet the effectiveness of LLM-based approaches in real-world applications remains under explored. This study measures the knowledge users acquire with topic models—including traditional, unsupervised and supervised LLM- based approaches—on two datasets. While LLM-based methods generate more human- readable topics and show higher average win probabilities than traditional models for data exploration, they produce overly generic topics for domain-specific datasets that do not easily allow users to learn much about the documents. Adding human supervision to LLM-based topic models improves data exploration by addressing hallucination and genericity but requires more human efforts. In contrast, traditional models like Latent Dirichlet Allocation (LDA) remain effective for exploration but are less user-friendly. This paper provides best practices—there is no one right model, the choice of models is situation-specific—and suggests potential improvements for scalable LLM- based topic models.

With their rapid advancements in research and growing popularity in various applications, we provide a comprehensive survey of VLMs. Specifically, we provide a systematic overview of VLMs in the following aspects:
cover:          /assets/images/covers/bass.png

authors:
  - Zongxia Li
  - Lorena Calvo-Bartolomé
  - Alexander Hoyle
  - Paiheng Xu
  - Daniel Stephens
  - Alden Dima
  - Juan Francisco Fung
  - Jordan Lee Boyd-Graber
links:
  Paper: https://arxiv.org/abs/2502.14748
  Huggingface: https://huggingface.co/datasets/zli12321/Bills
  
  
---
